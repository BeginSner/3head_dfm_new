{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x209fe66e2f0>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pdb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "seed = 2298839\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "sigmoid = lambda x: 1/(1+np.exp(-x))\n",
    "mse = lambda x,y: np.mean((x-y)**2)\n",
    "acc = lambda x,y: np.mean(x == y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>Load from yahoo data set<===\n",
      "[train] num data: 311704\n",
      "[test]  num data: 54000\n",
      "# user: 15400, # item: 1000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dataset import load_data, rating_mat_to_sample\n",
    "dataset_name = \"yahoo\"\n",
    "\n",
    "if dataset_name == \"coat\":\n",
    "    data_set_dir = os.path.join(\"../data\", dataset_name)\n",
    "    train_file = os.path.join(data_set_dir, \"train.ascii\")\n",
    "    test_file = os.path.join(data_set_dir, \"test.ascii\")\n",
    "    with open(train_file, \"r\") as f:\n",
    "        train_mat = []\n",
    "        for line in f.readlines():\n",
    "            train_mat.append(line.split())\n",
    "        train_mat = np.array(train_mat).astype(int)\n",
    "    with open(test_file, \"r\") as f:\n",
    "        test_mat = []\n",
    "        for line in f.readlines():\n",
    "            test_mat.append(line.split())\n",
    "        test_mat = np.array(test_mat).astype(int)\n",
    "    x_train, y_train = rating_mat_to_sample(train_mat)\n",
    "    x_test, y_test = rating_mat_to_sample(test_mat)\n",
    "    num_user = train_mat.shape[0]\n",
    "    num_item = train_mat.shape[1]\n",
    "else:\n",
    "    data_set_dir = os.path.join(\"../data\", dataset_name)\n",
    "    train_file = os.path.join(data_set_dir, \"train.txt\")\n",
    "    test_file = os.path.join(data_set_dir, \"test.txt\")\n",
    "    train_mat = []\n",
    "    # <user_id> <song id> <rating>\n",
    "    with open(train_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            train_mat.append(line.strip().split())\n",
    "    train_mat = np.array(train_mat).astype(int)\n",
    "\n",
    "    test_mat = []\n",
    "    # <user_id> <song id> <rating>\n",
    "    with open(test_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            test_mat.append(line.strip().split())\n",
    "    test_mat = np.array(test_mat).astype(int)\n",
    "    print(\"===>Load from {} data set<===\".format(dataset_name))\n",
    "    print(\"[train] num data:\", train_mat.shape[0])\n",
    "    print(\"[test]  num data:\", test_mat.shape[0])\n",
    "    num_user = train_mat[:, 0].max()\n",
    "    num_item = train_mat[:, 1].max()\n",
    "    x_train, y_train, x_test, y_test = train_mat[:, :-1], train_mat[:, -1], \\\n",
    "                                           test_mat[:, :-1], test_mat[:, -1]\n",
    "print(\"# user: {}, # item: {}\".format(num_user, num_item))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(311704,) (311704,) (311704,)\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, x_train[:,0].shape, x_train[:,1].shape)\n",
    "print(min(x_train[:,0]),min(x_train[:,1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "row index exceeds matrix dimensions",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m y_test \u001B[38;5;241m=\u001B[39m binarize(y_test)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m sparse \u001B[38;5;28;01mas\u001B[39;00m sps\n\u001B[1;32m----> 6\u001B[0m y_train_sparse \u001B[38;5;241m=\u001B[39m \u001B[43msps\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcsr_matrix\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mnum_user\u001B[49m\u001B[43m,\u001B[49m\u001B[43m                                     \u001B[49m\u001B[43mnum_item\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# (290, 300)\u001B[39;00m\n\u001B[0;32m      7\u001B[0m y_train_sparse \u001B[38;5;241m=\u001B[39m y_train_sparse\u001B[38;5;241m.\u001B[39mtoarray()\u001B[38;5;241m.\u001B[39mreshape(num_user \u001B[38;5;241m*\u001B[39m num_item) \u001B[38;5;66;03m# (87000, 1)\u001B[39;00m\n\u001B[0;32m      8\u001B[0m O_train_sparse \u001B[38;5;241m=\u001B[39m sps\u001B[38;5;241m.\u001B[39mcsr_matrix((np\u001B[38;5;241m.\u001B[39mones(\u001B[38;5;28mlen\u001B[39m(x_train[:, \u001B[38;5;241m0\u001B[39m])), (x_train[:, \u001B[38;5;241m0\u001B[39m], x_train[:, \u001B[38;5;241m1\u001B[39m])),                                  shape\u001B[38;5;241m=\u001B[39m(num_user, num_item), dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat32)\n",
      "File \u001B[1;32mC:\\Software\\Anaconda\\envs\\mlp\\lib\\site-packages\\scipy\\sparse\\_compressed.py:53\u001B[0m, in \u001B[0;36m_cs_matrix.__init__\u001B[1;34m(self, arg1, shape, dtype, copy)\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(arg1) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m     51\u001B[0m         \u001B[38;5;66;03m# (data, ij) format\u001B[39;00m\n\u001B[0;32m     52\u001B[0m         other \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m(\n\u001B[1;32m---> 53\u001B[0m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_coo_container\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     54\u001B[0m         )\n\u001B[0;32m     55\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_self(other)\n\u001B[0;32m     56\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(arg1) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m:\n\u001B[0;32m     57\u001B[0m         \u001B[38;5;66;03m# (data, indices, indptr) format\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Software\\Anaconda\\envs\\mlp\\lib\\site-packages\\scipy\\sparse\\_coo.py:197\u001B[0m, in \u001B[0;36mcoo_matrix.__init__\u001B[1;34m(self, arg1, shape, dtype, copy)\u001B[0m\n\u001B[0;32m    194\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    195\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m--> 197\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Software\\Anaconda\\envs\\mlp\\lib\\site-packages\\scipy\\sparse\\_coo.py:284\u001B[0m, in \u001B[0;36mcoo_matrix._check\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    282\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnnz \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    283\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrow\u001B[38;5;241m.\u001B[39mmax() \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]:\n\u001B[1;32m--> 284\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrow index exceeds matrix dimensions\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    285\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcol\u001B[38;5;241m.\u001B[39mmax() \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]:\n\u001B[0;32m    286\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcolumn index exceeds matrix dimensions\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: row index exceeds matrix dimensions"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "x_train, y_train = shuffle(x_train, y_train)\n",
    "y_train = binarize(y_train)\n",
    "y_test = binarize(y_test)\n",
    "from scipy import sparse as sps\n",
    "y_train_sparse = sps.csr_matrix((y_train, (x_train[:, 0], x_train[:, 1])), shape=(num_user,                                     num_item), dtype=np.float32) # (290, 300)\n",
    "y_train_sparse = y_train_sparse.toarray().reshape(num_user * num_item) # (87000, 1)\n",
    "O_train_sparse = sps.csr_matrix((np.ones(len(x_train[:, 0])), (x_train[:, 0], x_train[:, 1])),                                  shape=(num_user, num_item), dtype=np.float32)\n",
    "O_train_sparse = O_train_sparse.toarray().reshape(num_user * num_item)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MF] epoch:0, xent:nan\n",
      "[MF] epoch:10, xent:nan\n",
      "[MF] epoch:20, xent:nan\n",
      "[MF] epoch:30, xent:nan\n",
      "[MF] epoch:40, xent:nan\n",
      "[MF] epoch:50, xent:nan\n",
      "[MF] epoch:60, xent:nan\n",
      "[MF] epoch:70, xent:nan\n",
      "[MF] epoch:80, xent:nan\n",
      "[MF] epoch:90, xent:nan\n",
      "[MF] epoch:100, xent:nan\n",
      "[MF] epoch:110, xent:nan\n",
      "[MF] epoch:120, xent:nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m mf\u001B[38;5;241m.\u001B[39mcuda()\n\u001B[0;32m      6\u001B[0m hyper \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_epoch\u001B[39m\u001B[38;5;124m\"\u001B[39m:\u001B[38;5;241m1000\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch_size\u001B[39m\u001B[38;5;124m\"\u001B[39m:\u001B[38;5;241m128\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m\"\u001B[39m:\u001B[38;5;241m0.01\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlamb\u001B[39m\u001B[38;5;124m\"\u001B[39m:\u001B[38;5;241m1e-4\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtol\u001B[39m\u001B[38;5;124m\"\u001B[39m:\u001B[38;5;241m1e-5\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mverbose\u001B[39m\u001B[38;5;124m\"\u001B[39m:\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mG\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1\u001B[39m}\n\u001B[1;32m----> 7\u001B[0m \u001B[43mmf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhyper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_ips\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_train_sparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\delayed-feedback\\3head_dfm_new\\src\\models.py:73\u001B[0m, in \u001B[0;36mMF.fit\u001B[1;34m(self, x, y, hyper, y_ips)\u001B[0m\n\u001B[0;32m     71\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mxent_func(sub_y, pred)\n\u001B[0;32m     72\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 73\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     74\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     76\u001B[0m epoch_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "File \u001B[1;32mC:\\Software\\Anaconda\\envs\\mlp\\lib\\site-packages\\torch\\_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    486\u001B[0m     )\n\u001B[1;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Software\\Anaconda\\envs\\mlp\\lib\\site-packages\\torch\\autograd\\__init__.py:193\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    189\u001B[0m inputs \u001B[38;5;241m=\u001B[39m (inputs,) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(inputs, torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;28;01melse\u001B[39;00m \\\n\u001B[0;32m    190\u001B[0m     \u001B[38;5;28mtuple\u001B[39m(inputs) \u001B[38;5;28;01mif\u001B[39;00m inputs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mtuple\u001B[39m()\n\u001B[0;32m    192\u001B[0m grad_tensors_ \u001B[38;5;241m=\u001B[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001B[38;5;28mlen\u001B[39m(tensors))\n\u001B[1;32m--> 193\u001B[0m grad_tensors_ \u001B[38;5;241m=\u001B[39m \u001B[43m_make_grads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_grads_batched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    194\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m retain_graph \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n",
      "File \u001B[1;32mC:\\Software\\Anaconda\\envs\\mlp\\lib\\site-packages\\torch\\autograd\\__init__.py:89\u001B[0m, in \u001B[0;36m_make_grads\u001B[1;34m(outputs, grads, is_grads_batched)\u001B[0m\n\u001B[0;32m     87\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m out\u001B[38;5;241m.\u001B[39mnumel() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m     88\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgrad can be implicitly created only for scalar outputs\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 89\u001B[0m     new_grads\u001B[38;5;241m.\u001B[39mappend(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mones_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemory_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreserve_format\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     90\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     91\u001B[0m     new_grads\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\"MF\"\n",
    "from models import MF, MF_IPS, MF_SNIPS, MF_DR, MF_DR_JL\n",
    "embedding_k = 8\n",
    "mf = MF(num_user, num_item, embedding_k = embedding_k)\n",
    "mf.cuda()\n",
    "hyper = {\"num_epoch\":1000, \"batch_size\":128, \"lr\":0.01, \"lamb\":1e-4, \"tol\":1e-5, \"verbose\":False, \"G\": 1}\n",
    "mf.fit(x_train, y_train, hyper, y_ips=y_train_sparse)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample = generate_meshgrid(num_user, num_item) # (87000, 2)\n",
    "y_train_hat, emb= mf.predict(sample) # (87000, 1), (87000, 16)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sigma_h = 1\n",
    "W_d = np.random.normal(0, sigma_h, 2 * embedding_k) # (16,)\n",
    "lbd = np.exp(np.dot(emb, W_d)) # (87000,)\n",
    "D = np.random.exponential(lbd) # (87000,)\n",
    "\n",
    "L = np.quantile(D[y_train_sparse == 1], 0.6) # (1,) get the 60% value\n",
    "ts_click = np.random.uniform(0, L, num_user * num_item) # (87000,)\n",
    "E = L - ts_click # (87000,)\n",
    "idx = (D <= E)\n",
    "print(np.sum(y_train))\n",
    "y_train = y_train_sparse * idx\n",
    "print(np.sum(y_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train_sparse[O_train_sparse == 0] = -1\n",
    "E[y_train == 1] = D[y_train == 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data = np.c_[np.c_[np.c_[np.c_[np.array(sample), O_train_sparse], y_train_sparse], y_train], E]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.DataFrame(train_data, columns = ['Uid', 'Iid', 'O', 'C', 'Y_obs', 'E'])\n",
    "train_labels = np.c_[np.c_[np.c_[y_train_sparse, D], y_train], E]\n",
    "print(train_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(y_train[y_train==y_train_sparse].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(y_train[y_train*y_train_sparse==1].shape)\n",
    "print(set(y_train[y_train_sparse==-1])) # c=-1 -> yobs=0\n",
    "print(set(y_train))\n",
    "print(set(y_train-y_train_sparse))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"yobs=1: {y_train[y_train==1].shape}\")\n",
    "print(f\"yobs=0: {y_train[y_train==0].shape}\")\n",
    "print(f\"c=1: {y_train_sparse[y_train_sparse==1].shape}\")\n",
    "print(f\"c=-1: {y_train_sparse[y_train_sparse==-1].shape}\")\n",
    "print(f\"c=0: {y_train_sparse[y_train_sparse==0].shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(c = -1) -> no click -> (yobs = 0) -> 没看到 -> 1 − po\n",
    "(c = 0) -> no conversion -> (yobs = 0) -> 看到了不喜欢 -> po(1 − pc)\n",
    "(c = 1)*(D>E) -> (yobs = 0) -> 看到了，喜欢没来得及买 -> po*pc*exp(-λ*E)\n",
    "(c = 1)*(D<=E) -> (yobs = 1) -> 看到了，喜欢，买了 -> -(log(po) + log(pc) + log(λ) − λ*D)\n",
    "前三行加起来取负对数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_hat_bin = [1 if x>=0.5 else 0 for x in y_train_hat]\n",
    "yy = np.c_[np.array(y_train), np.array(y_hat_bin)].astype(int)\n",
    "yy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_test_pred, _ = mf.predict(x_test)\n",
    "y_test_pred = [1 if x>=0.5 else 0 for x in y_test_pred]\n",
    "print(f\"mse: {mse(y_test_pred, y_test)}\")\n",
    "print(f\"acc: {acc(y_test_pred, y_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Example true labels (0 and 1)\n",
    "y_label = [0, 0, 1, 1, 0, 1, 0, 1, 1, 0]\n",
    "\n",
    "# Example predicted probabilities for the positive class (1)\n",
    "pred_prob = [0.1, 0.4, 0.35, 0.8, 0.4, 0.9, 0.3, 0.75, 0.65, 0.5]\n",
    "\n",
    "# Compute the ROC AUC score\n",
    "auc = roc_auc_score(y_label, pred_prob)\n",
    "\n",
    "print(f\"ROC AUC score: {auc:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}